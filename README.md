
# ğŸ§  Rodando o MedGemma Localmente com Ollama + Open WebUI

Este repositÃ³rio contÃ©m o `Modelfile` necessÃ¡rio para executar o modelo **MedGemma** localmente usando o [Ollama](https://ollama.com/) e a interface web [Open WebUI](https://github.com/open-webui/open-webui).

---

## âš™ï¸ Requisitos

- âœ… [Ollama instalado](https://ollama.com/download)
- âœ… [Docker instalado](https://docs.docker.com/get-docker/)
- âœ… EspaÃ§o em disco (~10GB recomendado)

---

## ğŸ“¥ 1. Baixe o modelo `.gguf`

Baixe o modelo quantizado `medgemma-4b-it-Q8_0.gguf` do Hugging Face:

```bash
mkdir medgemma_build
cd medgemma_build

wget https://huggingface.co/kelkalot/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q8_0.gguf
```

ğŸ“ Certifique-se de que o arquivo `.gguf` esteja na **mesma pasta que o `Modelfile`** e coloque no `Modelfile`** o nome do seu arquivo `.gguf`.

---

## ğŸ§ª 2. Crie o modelo no Ollama

Com o `Modelfile` e o `.gguf` na mesma pasta, execute:

```bash
ollama create medgemma -f ./Modelfile
```

âœ… Isso registrarÃ¡ o modelo `medgemma` localmente no Ollama.

---

## ğŸ§  3. Rode o modelo com Ollama

```bash
ollama run medgemma
```

---

## ğŸŒ 4. Execute o Open WebUI via Docker

Execute este comando para iniciar a interface web local:

```bash
docker run -d -p 8080:8080 \
  -v open-webui:/app/backend/data \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```

ğŸ”— Depois, acesse:

```
http://localhost:8080
```

> ğŸ’¡ Caso esteja no Linux, substitua `host.docker.internal` por `127.0.0.1`.

---

## âœ… Verificando

VocÃª verÃ¡ o modelo `medgemma` disponÃ­vel no menu de modelos do Open WebUI. Basta selecionÃ¡-lo e comeÃ§ar a usar!

---

## ğŸ“Œ ObservaÃ§Ãµes

- O arquivo `.gguf` **nÃ£o estÃ¡ neste repositÃ³rio** por questÃµes de tamanho. FaÃ§a o download manual conforme mostrado acima.
- O modelo usa quantizaÃ§Ã£o `Q8_0`, ideal para resultados mais precisos (requer um pouco mais de RAM).
- O `Modelfile` jÃ¡ estÃ¡ configurado para rodar corretamente com o MedGemma.

---

## ğŸ“– CrÃ©ditos

- Modelo MedGemma convertido por: [`kelkalot`](https://huggingface.co/kelkalot/medgemma-4b-it-GGUF)
- Interface Web: [Open WebUI](https://github.com/open-webui/open-webui)
- Motor de execuÃ§Ã£o local: [Ollama](https://ollama.com/)
