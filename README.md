
# ğŸ§  Rodando o MedGemma Localmente com Ollama + Open WebUI

Este repositÃ³rio contÃ©m o `Modelfile` necessÃ¡rio para executar o modelo **MedGemma** localmente usando o [Ollama](https://ollama.com/) e a interface web [Open WebUI](https://github.com/open-webui/open-webui).

---

## âš™ï¸ Requisitos

- âœ… [Ollama instalado](https://ollama.com/download)
- âœ… [Docker instalado](https://docs.docker.com/get-docker/)
- âœ… EspaÃ§o em disco (~10GB recomendado)

---

## ğŸ“¥ 1. Baixe o modelo `.gguf`

Baixe o modelo quantizado `medgemma-4b-it-Q8_0.gguf` do Hugging Face:

```bash
mkdir medgemma_build
cd medgemma_build

wget https://huggingface.co/kelkalot/medgemma-4b-it-GGUF/resolve/main/medgemma-4b-it-Q8_0.gguf
```

ğŸ“ Certifique-se de que o arquivo `.gguf` esteja na **mesma pasta que o `Modelfile`** e coloque no `Modelfile` o nome do seu arquivo `.gguf`.

---

## ğŸš€ 2. Rodando tudo automaticamente com os scripts

Este repositÃ³rio jÃ¡ contÃ©m scripts prontos para automatizar a criaÃ§Ã£o do modelo e o deploy da interface web:

# â–¶ï¸ Windows
No terminal cmd ou PowerShell, execute:

```bash
setup-medgemma.bat
```

# ğŸ§ Linux/macOS
DÃª permissÃ£o de execuÃ§Ã£o:
```bash
chmod +x setup-medgemma.sh
```

Depois, execute:

```bash
./setup-medgemma.sh
```

Esse script:

âœ”ï¸ Cria o modelo no Ollama (se ainda nÃ£o existir)
âœ”ï¸ Inicia o Open WebUI via Docker

## ğŸŒ 3. Acesse a interface

```arduino
(http://localhost:8080)
```
---

## âœ… Verificando

VocÃª verÃ¡ o modelo `medgemma` disponÃ­vel no menu de modelos do Open WebUI. Basta selecionÃ¡-lo e comeÃ§ar a usar!

---

## ğŸ“Œ ObservaÃ§Ãµes

- O arquivo `.gguf` **nÃ£o estÃ¡ neste repositÃ³rio** por questÃµes de tamanho. FaÃ§a o download manual conforme mostrado acima.
- O modelo usa quantizaÃ§Ã£o `Q8_0`, ideal para resultados mais precisos (requer um pouco mais de RAM).
- O `Modelfile` jÃ¡ estÃ¡ configurado para rodar corretamente com o MedGemma.

---

## ğŸ“– CrÃ©ditos

- Modelo MedGemma convertido por: [`kelkalot`](https://huggingface.co/kelkalot/medgemma-4b-it-GGUF)
- Interface Web: [Open WebUI](https://github.com/open-webui/open-webui)
- Motor de execuÃ§Ã£o local: [Ollama](https://ollama.com/)
